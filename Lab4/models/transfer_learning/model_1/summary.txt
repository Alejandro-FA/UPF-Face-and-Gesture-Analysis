Validation results: {'loss': [4.9558892250061035, 4.283755302429199, 3.725703001022339, 3.2972617149353027, 2.960932493209839, 2.705266237258911, 2.4979262351989746, 2.3339686393737793, 2.201979160308838, 2.097846269607544, 2.003605604171753, 1.926719307899475, 1.8685086965560913, 1.8071978092193604, 1.7586921453475952, 1.7174110412597656, 1.6848363876342773, 1.6503989696502686, 1.6146516799926758, 1.595578670501709, 1.5688483715057373, 1.5511860847473145, 1.5334872007369995, 1.5098987817764282, 1.499622106552124, 1.494126558303833, 1.4806506633758545, 1.477683186531067, 1.4763554334640503, 1.4756419658660889, 1.4747287034988403, 1.4744764566421509, 1.474340796470642, 1.474171757698059, 1.4740656614303589, 1.4739749431610107, 1.4737911224365234, 1.4736722707748413, 1.473609209060669, 1.4735133647918701, 1.473379135131836, 1.4732511043548584, 1.4731619358062744, 1.4730478525161743, 1.4728748798370361, 1.472739338874817, 1.4725884199142456, 1.4724681377410889, 1.472438097000122, 1.4723231792449951], 'accuracy': [3.75, 5.625, 16.25, 23.125, 31.25, 36.25, 40.625, 45.625, 46.875, 48.125, 50.625, 54.375, 55.0, 55.0, 57.5, 57.5, 57.5, 58.125, 58.125, 60.0, 60.0, 59.375, 60.0, 60.0, 60.0, 61.25, 61.25, 60.625, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875, 61.875]}
Loss function used: CrossEntropyLoss()
Epochs: 50
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 1e-05
    maximize: False
    weight_decay: 0.005
)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
superlight_network_9layers               [512, 80]                 --
├─Sequential: 1-1                        [512, 48, 8, 8]           --
│    └─mfm: 2-1                          [512, 16, 128, 128]       --
│    │    └─Conv2d: 3-1                  [512, 32, 128, 128]       2,432
│    └─MaxPool2d: 2-2                    [512, 16, 64, 64]         --
│    └─mfm: 2-3                          [512, 32, 64, 64]         --
│    │    └─Conv2d: 3-2                  [512, 64, 64, 64]         9,280
│    └─MaxPool2d: 2-4                    [512, 32, 32, 32]         --
│    └─group: 2-5                        [512, 64, 32, 32]         --
│    │    └─mfm: 3-3                     [512, 32, 32, 32]         2,112
│    │    └─mfm: 3-4                     [512, 64, 32, 32]         36,992
│    └─MaxPool2d: 2-6                    [512, 64, 16, 16]         --
│    └─group: 2-7                        [512, 48, 16, 16]         --
│    │    └─mfm: 3-5                     [512, 64, 16, 16]         8,320
│    │    └─mfm: 3-6                     [512, 48, 16, 16]         55,392
│    └─group: 2-8                        [512, 48, 16, 16]         --
│    │    └─mfm: 3-7                     [512, 48, 16, 16]         4,704
│    │    └─mfm: 3-8                     [512, 48, 16, 16]         41,568
│    └─MaxPool2d: 2-9                    [512, 48, 8, 8]           --
├─mfm: 1-2                               [512, 128]                --
│    └─Linear: 2-10                      [512, 256]                786,688
├─Linear: 1-3                            [512, 80]                 10,320
==========================================================================================
Total params: 957,808
Trainable params: 957,808
Non-trainable params: 0
Total mult-adds (G): 75.19
==========================================================================================
Input size (MB): 100.66
Forward/backward pass size (MB): 4464.12
Params size (MB): 3.83
Estimated Total Size (MB): 4568.61
==========================================================================================