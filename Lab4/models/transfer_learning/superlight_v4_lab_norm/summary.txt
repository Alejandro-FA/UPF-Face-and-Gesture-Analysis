Validation results: {'loss': [3.0880617618560793, 1.9176873683929443, 1.5778677368164062, 1.4190211820602416, 1.3041823244094848, 1.2364192581176758, 1.181346607208252, 1.1416324949264527, 1.1118416213989257, 1.0879014587402345, 1.0681903266906738, 1.0591027545928955, 1.0522911596298217, 1.043634204864502, 1.0388864994049072, 1.0384464359283447, 1.0364492559432983, 1.035853328704834, 1.0355620193481445, 1.0355669164657593, 1.0354525804519654, 1.0354184627532959, 1.0354030418395996, 1.0353908824920655, 1.035380802154541, 1.0353599071502686, 1.0353524160385132, 1.0353351545333862, 1.0353017044067383, 1.0352839851379394, 1.0352748203277589, 1.0352676963806153, 1.0352298021316528, 1.0352120780944825, 1.0352062320709228, 1.0351916313171388, 1.0351786613464355, 1.0351570415496827, 1.035146656036377, 1.0351476097106933, 1.0351256561279296, 1.0351095962524415, 1.0350992345809937, 1.035090789794922, 1.0350884532928466, 1.0350650978088378, 1.0350367975234986, 1.0350291347503662, 1.0350107049942017, 1.0350003480911254, 1.0349878978729248, 1.0349820137023926, 1.0349490690231322, 1.034942488670349, 1.03491313457489, 1.0349076557159425, 1.0348988437652589, 1.0348954105377197, 1.0348632431030274, 1.0348478317260743, 1.0348270082473754, 1.0348128509521484, 1.0348004722595214, 1.0347865676879884, 1.0347686052322387, 1.034754467010498, 1.0347421979904174, 1.0347165870666504, 1.0347086238861083, 1.0346839475631713, 1.0346834468841553, 1.0346532773971557, 1.0346435451507567, 1.03464035987854, 1.0346354484558105, 1.034600772857666, 1.0345716190338134, 1.0345400810241698, 1.0345416927337647, 1.034508810043335, 1.0345024299621581, 1.0344730377197267, 1.0344543075561523, 1.0344400358200074, 1.0344325017929077, 1.034405608177185, 1.0343947410583496, 1.0343677949905397, 1.0343540000915528, 1.0343436241149901, 1.0343338203430177, 1.0343072605133057, 1.0343073654174804, 1.0342725944519042, 1.034253306388855, 1.0342407083511354, 1.0342167377471925, 1.0342033338546752, 1.034182481765747, 1.0341584253311158, 1.0341427183151246, 1.0341210508346557, 1.034083366394043, 1.0340703296661378, 1.0340509128570556, 1.0340440559387207, 1.0340269088745118, 1.034010362625122, 1.0339994573593139, 1.033988552093506, 1.0339727544784545, 1.0339773893356323, 1.0339485263824464, 1.0339287185668946, 1.0339221668243408, 1.0339195775985717, 1.0338985204696656, 1.0338727188110353, 1.0338757991790772, 1.0338526964187622, 1.0338302373886108, 1.0338454389572143, 1.0338193321228026, 1.033790988922119, 1.0337688875198365, 1.0337487268447876, 1.033727731704712, 1.033721046447754, 1.0336978721618653, 1.0336920499801636, 1.0336726188659668, 1.0336691045761108, 1.0336538982391357, 1.0336195278167724, 1.0335947036743165, 1.0335787963867187, 1.0335874795913695, 1.033544545173645, 1.0335269737243653, 1.0335213136672974, 1.0334897613525391, 1.03345609664917, 1.0334271574020386, 1.033417272567749, 1.033390302658081, 1.0333686256408692, 1.0333476972579956, 1.0333215713500976, 1.0333026123046876, 1.0333057832717896, 1.0332804918289185, 1.0332578945159911, 1.0332403945922852, 1.0332174348831176, 1.033191909790039, 1.0331824445724487, 1.0331316995620727, 1.0331300544738768, 1.0331004905700683, 1.0331095123291016, 1.0331054401397706, 1.0330646324157715, 1.033063201904297, 1.0330335760116578, 1.033013997077942, 1.0330148792266847, 1.0329917097091674, 1.0329850673675538, 1.0329744625091553, 1.0329526090621948, 1.032923183441162, 1.0329150581359863, 1.032896499633789, 1.0328765678405762, 1.0328730201721192, 1.0328570890426636, 1.0328306007385253, 1.0328226137161254, 1.0327862358093263, 1.0327868747711182, 1.032753314971924, 1.0327216482162476, 1.032712655067444, 1.0326836681365967, 1.032682590484619, 1.0326775550842284, 1.0326430892944336, 1.032653079032898, 1.032634334564209, 1.0326115560531617, 1.032590069770813, 1.0325611400604249, 1.032546844482422, 1.0325014352798463, 1.0324954748153687, 1.0324804639816285, 1.0324539613723756, 1.03242262840271, 1.0324193477630614, 1.0324049186706543], 'accuracy': [32.5, 63.375, 71.5, 73.25, 74.625, 75.25, 75.5, 75.875, 75.625, 75.625, 75.25, 75.5, 75.75, 75.625, 75.375, 75.5, 75.5, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625, 75.625]}
Loss function used: CrossEntropyLoss()
Epochs: 200
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 1e-06
    maximize: False
    weight_decay: 0
)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
superlight_cnn_v4                        [512, 80]                 --
├─inception_mfm: 1-1                     [512, 16, 128, 128]       --
│    └─mfm_v3: 2-1                       [512, 8, 128, 128]        --
│    │    └─Conv2d: 3-1                  [512, 16, 128, 128]       1,216
│    └─mfm_v3: 2-2                       [512, 8, 128, 128]        --
│    │    └─Conv2d: 3-2                  [512, 16, 128, 128]       2,368
├─inception_mfm: 1-2                     [512, 32, 64, 64]         --
│    └─mfm_v3: 2-3                       [512, 16, 64, 64]         --
│    │    └─Conv2d: 3-3                  [512, 32, 64, 64]         4,640
│    └─mfm_v3: 2-4                       [512, 16, 64, 64]         --
│    │    └─Conv2d: 3-4                  [512, 32, 64, 64]         12,832
├─group_v3: 1-3                          [512, 64, 32, 32]         --
│    └─mfm_v3: 2-5                       [512, 32, 32, 32]         --
│    │    └─Conv2d: 3-5                  [512, 64, 32, 32]         2,112
│    └─mfm_v3: 2-6                       [512, 64, 32, 32]         --
│    │    └─Conv2d: 3-6                  [512, 128, 32, 32]        36,992
├─group_v3: 1-4                          [512, 48, 16, 16]         --
│    └─mfm_v3: 2-7                       [512, 64, 16, 16]         --
│    │    └─Conv2d: 3-7                  [512, 128, 16, 16]        8,320
│    └─mfm_v3: 2-8                       [512, 48, 16, 16]         --
│    │    └─Conv2d: 3-8                  [512, 96, 16, 16]         55,392
├─group_v3: 1-5                          [512, 48, 16, 16]         --
│    └─mfm_v3: 2-9                       [512, 48, 16, 16]         --
│    │    └─Conv2d: 3-9                  [512, 96, 16, 16]         4,704
│    └─mfm_v3: 2-10                      [512, 48, 16, 16]         --
│    │    └─Conv2d: 3-10                 [512, 96, 16, 16]         41,568
├─mfm_v3: 1-6                            [512, 133]                --
│    └─Linear: 2-11                      [512, 266]                817,418
├─Linear: 1-7                            [512, 80]                 10,720
==========================================================================================
Total params: 998,282
Trainable params: 998,282
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 102.05
==========================================================================================
Input size (MB): 100.66
Forward/backward pass size (MB): 4464.16
Params size (MB): 3.99
Estimated Total Size (MB): 4568.81
==========================================================================================